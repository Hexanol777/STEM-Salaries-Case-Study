{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iut](https://github.com/Hexanol777/STEM-Salaries-Case-Study/tree/main/Phase%201/stock_image/IUT200.png)\n",
    "<hr style=\"margin-bottom: 40px;\">\n",
    "\n",
    "\n",
    "# STEM Jobs Salaries - Classification\n",
    "\n",
    "## Classification\n",
    "\n",
    "#### Classification is a fundamental task in machine learning and data analysis that involves categorizing data into predefined classes or categories based on their features or attributes. It is a supervised learning technique where the goal is to train a model on labeled training data to make accurate predictions on unseen or test data.\n",
    "\n",
    "[Link to the Data used in this Notebook](https://drive.google.com/file/d/1IhXv0qcq7YFfBxc0BQB1-z74wF40ZnZn/view?usp=share_link)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## Data Extraction - Importing Modules\n",
    "\n",
    " During the data extraction phase, we obtained the data directly from [kaggle.com](www.kaggle.com), which is a popular platform for accessing and sharing datasets. By using Kaggle, we were able to search for and download datasets that were relevant to our analysis which in this case is STEM Jobs Salaries, and we could be confident in the quality of the data provided, as the usability of it was rated 10 in the website. Overall, the data extraction phase was streamlined and efficient, thanks to the availability and accessibility of high-quality data on Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.ParserWarning)\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Loading The Initial Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!head data/STEMJobs.csv\n",
    "# Note: incase if you are running this line locally you will be met with the error below\n",
    "# as this notebook is meant to be executed in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\n",
    "    'data/STEM.csv',\n",
    "    parse_dates=['Timestamp'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Data First Look:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Data Types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Experienced, Non-experienced Classification\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['Experienced'] = pd.cut(Data['YearsOfExperience'], bins=[0, 8 , Data.YearsOfExperience.max()], labels=['Unexperienced', 'Experienced'])\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "exp_counts = Data.Experienced.value_counts()\n",
    "print(exp_counts)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.bar(exp_counts.index, exp_counts.values)\n",
    "plt.title('Experienced vs. Non-Experienced')\n",
    "plt.xlabel('Category')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Data Discretization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "deciles = pd.qcut(Data['TotalYearlyCompensation'], q=2, labels=False, duplicates='drop')\n",
    "decile_table = Data.groupby(deciles)['TotalYearlyCompensation'].describe()\n",
    "print(decile_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Very Low Income', 'Low Income', 'Moderate Income', 'High Income', 'Very High Income']\n",
    "counts = [10203, 9988, 9993, 9921, 10025]\n",
    "pay = [78290, 140733, 184321, 241417, 411220]\n",
    "\n",
    "# bar width\n",
    "bar_width = 0.35\n",
    "\n",
    "# array indices for the x axis\n",
    "x = np.arange(len(labels))\n",
    "\n",
    "# bar chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.bar(x - bar_width/2, counts, bar_width, label='Count')\n",
    "plt.bar(x + bar_width/2, pay, bar_width, label='Average Pay')\n",
    "\n",
    "# label and titles\n",
    "plt.xlabel('Income Categories')\n",
    "plt.ylabel('Count / Average Pay')\n",
    "plt.title('Distribution of Income')\n",
    "plt.xticks(x, labels, rotation=45)\n",
    "plt.legend()\n",
    "\n",
    "# displaying the chart\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Binary Encoding - Experienced\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.Experienced = np.where(Data.Experienced == 'Experienced', 1, 0)\n",
    "Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Label Column - Income\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['Lowerclass']\n",
    "Data['IncomeLevel'] = pd.cut(Data['TotalYearlyCompensation'], bins=[0, 210000 , Data.TotalYearlyCompensation.max()], labels=['LowerClass', 'HigherClass'])\n",
    "Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "income_counts = Data['IncomeLevel'].value_counts()\n",
    "print(income_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Income Level Binary Encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "Data.IncomeLevel = np.where(Data.IncomeLevel == 'HigherClass', 1, 0)\n",
    "Data\n",
    "\n",
    "frame = Data\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## LogReg for Experienced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "x = Data.drop(['YearsOfExperience', 'Experienced', 'Timestamp', 'Level', 'Company', 'Title', 'Country', 'IsUS', 'IsCA', 'IsID', 'IsIN'\n",
    "               , 'IsDE', 'Tag', 'Gender', 'Education'], axis=1)\n",
    "y = Data.Experienced\n",
    "\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(model, x_train, y_train, cv=5)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "\n",
    "# Assuming you have predicted probabilities or scores for the positive class\n",
    "y_scores = model.predict_proba(x_test)[:, 1]\n",
    "\n",
    "# Calculate the False Positive Rate (FPR) and True Positive Rate (TPR)\n",
    "fpr, tpr, _ = roc_curve(y_test, y_scores)\n",
    "\n",
    "# Calculate the AUC score\n",
    "auc = roc_auc_score(y_test, y_scores)\n",
    "\n",
    "print(auc)\n",
    "# Plot the ROC curve\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {auc:.2f}')\n",
    "plt.plot([0, 1], [0, 1], 'r--')\n",
    "plt.xlim([0, 1])\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('False Positive Rate (FPR)')\n",
    "plt.ylabel('True Positive Rate (TPR)')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## KNN for Experienced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "x = Data.drop(['YearsOfExperience', 'Experienced', 'Timestamp', 'Level', 'Company', 'Title', 'Country', 'IsUS', 'IsCA', 'IsID', 'IsIN'\n",
    "               , 'IsDE', 'Tag', 'Gender', 'Education'], axis=1)\n",
    "y = Data.Experienced\n",
    "\n",
    "\n",
    "# Define the range of k values\n",
    "k_values = range(1, 21)\n",
    "\n",
    "# Create a dictionary to store the accuracy for each k\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Iterate over each k value\n",
    "for k in k_values:\n",
    "    # Create and fit the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict labels for the test set\n",
    "    y_pred = knn.predict(x_test)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracy_scores[k] = accuracy\n",
    "\n",
    "# Sort the accuracy scores in descending order\n",
    "sorted_accuracy = sorted(accuracy_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the accuracy scores for each k in descending order\n",
    "for k, accuracy in sorted_accuracy:\n",
    "    print(f\"k = {k}: Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Random Forest for Experienced\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "# Create a Random Forest classifier with default parameters\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "# Calculate the accuracy of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", auc_roc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## LogReg for Income Level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "\n",
    "\n",
    "model = LogisticRegression()\n",
    "\n",
    "scores = cross_val_score(model, x_train, y_train, cv=5)\n",
    "\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(\"Cross-Validation Scores:\", scores)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", auc_roc)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## KNN for Income Level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = frame.drop(['Bonus', 'BaseSalary', 'StockGrantValue', 'TotalYearlyCompensation', 'Experienced', 'Timestamp', 'Level', 'Company', 'Title', 'Country', 'IsUS', 'IsCA', 'IsID', 'IsIN'\n",
    "               , 'IsDE', 'Tag', 'Gender', 'Education', 'IncomeLevel'], axis=1)\n",
    "y = frame[['IncomeLevel']]\n",
    "\n",
    "\n",
    "# Define the range of k values\n",
    "k_values = range(1, 21)\n",
    "\n",
    "# Create a dictionary to store the accuracy for each k\n",
    "accuracy_scores = {}\n",
    "\n",
    "# Iterate over each k value\n",
    "for k in k_values:\n",
    "    # Create and fit the KNN classifier\n",
    "    knn = KNeighborsClassifier(n_neighbors=k)\n",
    "    knn.fit(x_train, y_train)\n",
    "    \n",
    "    # Predict labels for the test set\n",
    "    y_pred = knn.predict(x_test)\n",
    "    \n",
    "    # Calculate the accuracy score\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Store the accuracy in the dictionary\n",
    "    accuracy_scores[k] = accuracy\n",
    "\n",
    "# Sort the accuracy scores in descending order\n",
    "sorted_accuracy = sorted(accuracy_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Print the accuracy scores for each k in descending order\n",
    "for k, accuracy in sorted_accuracy:\n",
    "    print(f\"k = {k}: Accuracy = {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=6)\n",
    "knn.fit(x_train, y_train)\n",
    "y_pred = knn.predict(x_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='macro')\n",
    "recall = recall_score(y_test, y_pred, average='macro')\n",
    "auc_roc = roc_auc_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"AUC-ROC:\", auc_roc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Random Forest for Income Level\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "x = frame.drop(['Bonus', 'BaseSalary', 'StockGrantValue', 'TotalYearlyCompensation', 'Experienced', 'Timestamp', 'Level', 'Company', 'Title', 'Country', 'IsUS', 'IsCA', 'IsID', 'IsIN'\n",
    "               , 'IsDE', 'Tag', 'Gender', 'Education', 'IncomeLevel'], axis=1)\n",
    "y = frame[['IncomeLevel']]\n",
    "\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, train_size=0.8)\n",
    "\n",
    "\n",
    "# Create a Random Forest classifier with default parameters\n",
    "rf_classifier = RandomForestClassifier()\n",
    "\n",
    "# Train the classifier on the training data\n",
    "rf_classifier.fit(x_train, y_train)\n",
    "\n",
    "# Make predictions on the test data\n",
    "y_pred = rf_classifier.predict(x_test)\n",
    "\n",
    "# Calculate the metrics of the classifier\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.title('Confusion Matrix')\n",
    "plt.xticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.yticks(ticks=[0.5, 1.5], labels=['0', '1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## free me from this suffering\n",
    "\n",
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
