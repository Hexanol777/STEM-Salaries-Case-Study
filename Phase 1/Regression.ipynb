{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![iut](https://github.com/Hexanol777/STEM-Salaries-Case-Study/tree/main/Phase%201/stock_image/IUT200.png)\n",
    "<hr style=\"margin-bottom: 40px;\">\n",
    "\n",
    "<img src=\"https://github.com/Hexanol777/STEM-Salaries-Case-Study/tree/main/Phase%201/stock_image/reg.png\"\n",
    "    style=\"width:400px; float: right; margin: 0 40px 40px 40px;\"></img>\n",
    "\n",
    "# STEM Jobs Salaries\n",
    "\n",
    "## Regression\n",
    "\n",
    "#### During the regressionphase of our data analysis, We used a variety of machine learning algorithms, including ElasticNet and Lasso regression, throughout the regression and model training stage of our data analysis to create models that could forecast the base income of STEM professionals based on a collection of features. These models were developed using the Scikit-Learn toolkit, and our preprocessed dataset served as their training ground. To make sure that our models weren't overfitting the data, we also used cross-validation. Metrics like mean squared error (MSE) and R-squared score were used to assess how well the models performed. \n",
    "\n",
    "[Link to the Data used in this Notebook](https://drive.google.com/file/d/1IhXv0qcq7YFfBxc0BQB1-z74wF40ZnZn/view?usp=share_link)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n",
    "\n",
    "## Importing Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Loading and Sampling the Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(\n",
    "    'data/jobs_with_country_codes.csv',\n",
    "    parse_dates=['Timestamp'])\n",
    "Data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Linear Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the features and target variable\n",
    "features  = ['YearsOfExperience', 'YearsAtCompany', 'IsUS', 'IsCA', 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']\n",
    "target = 'BaseSalary'\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_data = Data.sample(frac=0.8, random_state=1)\n",
    "test_data = Data.drop(train_data.index)\n",
    "\n",
    "\n",
    "# Train the model\n",
    "model = LinearRegression().fit(train_data[features], train_data[target])\n",
    "\n",
    "# Predict the target variable for the testing set\n",
    "predictions = model.predict(test_data[features])\n",
    "\n",
    "\n",
    "# Calculate the mean squared error and R-squared score\n",
    "mse = mean_squared_error(test_data[target], predictions)\n",
    "r2 = r2_score(test_data[target], predictions)\n",
    "\n",
    "print('Mean squared error: {:.2f}'.format(mse))\n",
    "print('R-squared score: {:.2f}'.format(r2))\n",
    "print('Coefficients used for this model are as : \\n',model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Polynomial Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# select the features and target variable\n",
    "X = Data[['YearsOfExperience', 'YearsAtCompany', 'IsUS', 'IsCA', 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']]\n",
    "y = Data['BaseSalary']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# train a linear regression model on the polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# evaluate the model using mean squared error and r-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean squared error:', mse)\n",
    "print('R-squared score:', r2)\n",
    "print('Coefficients used for this model are as : \\n',model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Ridge Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "\n",
    "# Select features and target\n",
    "X = Data[['YearsOfExperience', 'YearsAtCompany', 'IsUS', 'IsCA', 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']]\n",
    "y = Data['BaseSalary']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Fit the Ridge Regression model\n",
    "ridge = Ridge(alpha=0.1, random_state=42)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "# Predict the target variable for the test set\n",
    "y_pred = ridge.predict(X_test)\n",
    "\n",
    "# Evaluate the model using Mean Squared Error (MSE) and R-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print('Coefficients used for this model are as : \\n',ridge.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Lasso Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Select the features and target\n",
    "features = ['YearsOfExperience', 'YearsAtCompany', 'IsUS', 'IsCA', 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']\n",
    "target = ['BaseSalary']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(Data[features], Data[target], test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Polynomial features\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "X_train_poly = poly.fit_transform(X_train_scaled)\n",
    "X_test_poly = poly.transform(X_test_scaled)\n",
    "\n",
    "# Train the model\n",
    "lasso = Lasso(alpha=0.1, random_state=42, max_iter=1000)\n",
    "lasso.fit(X_train_poly, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = lasso.predict(X_test_poly)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print('Mean squared error:', mse)\n",
    "print('R-squared score:', r2)\n",
    "print('Coefficients used for this model are as : \\n',lasso.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## ElasticNet Regression\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# define the features and target variable\n",
    "features = ['YearsOfExperience', 'YearsAtCompany', 'IsUS', 'IsCA', 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']\n",
    "target = 'BaseSalary'\n",
    "\n",
    "# create X and y arrays\n",
    "X = Data[features]\n",
    "y = Data[target]\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# set hyperparameters alpha and l1_ratio\n",
    "alpha = 0.5\n",
    "l1_ratio = 0.5\n",
    "\n",
    "# define the ElasticNet model with default hyperparameters\n",
    "model = make_pipeline(PolynomialFeatures(2), ElasticNet(alpha=alpha, l1_ratio=l1_ratio))\n",
    "\n",
    "# fit the model on the training data\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# make predictions on the test data\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# print the model coefficients\n",
    "coefs = model.named_steps['elasticnet'].coef_\n",
    "intercept = model.named_steps['elasticnet'].intercept_\n",
    "equation = \"y = {:.2f}\".format(intercept)\n",
    "for i, coef in enumerate(coefs):\n",
    "    if i == 0:\n",
    "        equation += \" + {:.2f}\".format(coef)\n",
    "    else:\n",
    "        if coef >= 0:\n",
    "            equation += \" + {:.2f}x{}\".format(coef, i)\n",
    "        else:\n",
    "            equation += \" - {:.2f}x{}\".format(abs(coef), i)\n",
    "\n",
    "\n",
    "# calculate and print evaluation metrics\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "print(\"Mean squared error: {:.2f}\".format(mse))\n",
    "print(\"R-squared score: {:.2f}\".format(r2))\n",
    "print(\"Model equation:\\n\", equation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## More Feature Scaling?\n",
    "\n",
    "By adding the encoding column `'IsUS'`, `'IsCA'`, `'IsID'`, `'IsIN'`, `'IsDE'`, `'IsMale'`, and `'IsFemale'` to our dataset, we were able to perform scaling on our data, which helped to decrease the mean squared error (MSE) of our model and increase the R-squared score. This is because scaling the data helps to normalize the values within the dataset, reducing the effect of outliers and making it easier for our model to learn patterns in the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "dataframe = Data\n",
    "X_s = dataframe[['BaseSalary', 'StockGrantValue', 'Bonus']].values\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X_s)\n",
    "\n",
    "# Replace the original columns with the scaled columns in the dataframe\n",
    "dataframe[['BaseSalary', 'StockGrantValue', 'Bonus']] = X_scaled\n",
    "\n",
    "# select the features and target variable\n",
    "X = Data[['YearsOfExperience', 'YearsAtCompany', 'StockGrantValue', 'Bonus', 'IsUS', 'IsCA'\n",
    "          , 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree']]\n",
    "\n",
    "y = Data['BaseSalary']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# train a linear regression model on the polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# evaluate the model using mean squared error and r-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean squared error:', mse)\n",
    "print('R-squared score:', r2)\n",
    "print('Coefficients used for this model are as : \\n',model.coef_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Even More Scaling?\n",
    "\n",
    "Adding the company encode column only provided us with a mere 0.02 R2-score increase, which isn't worth it for the sake of model complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_scaled = pd.read_csv(\n",
    "    'data/jobs_with_country_codes Scaled.csv',\n",
    "    parse_dates=['Timestamp'])\n",
    "data_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_s = data_scaled[['BaseSalary', 'StockGrantValue', 'Bonus']].values\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X_s)\n",
    "\n",
    "# Replace the original columns with the scaled columns in the dataframe\n",
    "data_scaled[['BaseSalary', 'StockGrantValue', 'Bonus']] = X_scaled\n",
    "\n",
    "\n",
    "# select the features and target variable\n",
    "X = data_scaled[['YearsOfExperience', 'YearsAtCompany', 'StockGrantValue', 'Bonus', 'IsUS', 'IsCA'\n",
    "          , 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree'\n",
    "          , 'IsSE', 'IsPM', 'IsSEM', 'IsDS', 'IsHE', 'IsAmazon', 'IsMicro', 'IsGoogle', 'IsFacebook', 'IsApple']]\n",
    "\n",
    "y = data_scaled['BaseSalary']\n",
    "\n",
    "# split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_train_poly = poly.fit_transform(X_train)\n",
    "X_test_poly = poly.transform(X_test)\n",
    "\n",
    "# train a linear regression model on the polynomial features\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_poly, y_train)\n",
    "\n",
    "# make predictions on the test set\n",
    "y_pred = model.predict(X_test_poly)\n",
    "\n",
    "# evaluate the model using mean squared error and r-squared score\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print('Mean squared error:', mse)\n",
    "print('R-squared score:', r2)\n",
    "print('Coefficients used for this model are as : \\n',model.coef_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![green-divider](https://user-images.githubusercontent.com/7065401/52071924-c003ad80-2562-11e9-8297-1c6595f8a7ff.png)\n",
    "\n",
    "## Cross Validation?\n",
    "\n",
    "Cross-validation is a statistical method used to estimate the performance of a machine learning model. The process involves partitioning a dataset into k equally sized parts or folds, where k is typically set to 5 or 10. One of the folds is held out as the validation set, while the other k-1 folds are used to train the model. This process is repeated k times, with each of the k folds used exactly once as the validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "X_s = data_scaled[['BaseSalary', 'StockGrantValue', 'Bonus']].values\n",
    "\n",
    "# Create a StandardScaler object\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit and transform the data\n",
    "X_scaled = scaler.fit_transform(X_s)\n",
    "\n",
    "# Replace the original columns with the scaled columns in the dataframe\n",
    "data_scaled[['BaseSalary', 'StockGrantValue', 'Bonus']] = X_scaled\n",
    "\n",
    "\n",
    "# select the features and target variable\n",
    "X = data_scaled[['YearsOfExperience', 'YearsAtCompany', 'StockGrantValue', 'Bonus', 'IsUS', 'IsCA'\n",
    "          , 'IsID', 'IsIN', 'IsDE', 'IsMale', 'IsFemale', 'Masters_Degree', 'Bachelors_Degree'\n",
    "          , 'IsSE', 'IsPM', 'IsSEM', 'IsDS', 'IsHE', 'IsAmazon', 'IsMicro', 'IsGoogle', 'IsFacebook', 'IsApple']]\n",
    "\n",
    "y = data_scaled['BaseSalary']\n",
    "\n",
    "# create polynomial features\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "\n",
    "\n",
    "# train a linear regression model on the polynomial features\n",
    "model = LinearRegression()\n",
    "\n",
    "# Perform k-fold cross validation\n",
    "k = 5  # Number of folds\n",
    "scores = cross_val_score(model, X, y, cv=k, scoring='neg_mean_squared_error')\n",
    "\n",
    "# Calculate the mean squared error for each fold\n",
    "mse_scores = -scores  # Convert negative scores to positive\n",
    "mean_mse = np.mean(mse_scores)\n",
    "\n",
    "# Print the mean squared error for each fold and the overall mean squared error\n",
    "print('MSE Scores:', mse_scores)\n",
    "print('Mean MSE:', mean_mse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![purple-divider](https://user-images.githubusercontent.com/7065401/52071927-c1cd7100-2562-11e9-908a-dde91ba14e59.png)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
